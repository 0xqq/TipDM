package com.tipdm.framework.dmserver.task.job;

import com.alibaba.fastjson.JSON;
import com.tipdm.framework.common.Constants;
import com.tipdm.framework.common.utils.RedisUtils;
import com.tipdm.framework.dmserver.core.task.schedule.TaskScheduler;
import com.tipdm.framework.dmserver.core.task.schedule.WorkFlow;
import com.tipdm.framework.dmserver.core.task.schedule.WorkFlowScheduler;
import com.tipdm.framework.dmserver.utils.RedissonUtils;
import com.tipdm.framework.model.dmserver.Document;
import com.tipdm.framework.model.dmserver.Project;
import com.tipdm.framework.model.dmserver.Task;
import com.tipdm.framework.service.dmserver.ProjectService;
import com.tipdm.framework.service.dmserver.TaskService;
import org.apache.commons.io.FileUtils;
import org.quartz.JobDataMap;
import org.quartz.JobExecutionContext;
import org.quartz.JobExecutionException;
import org.quartz.SchedulerException;
import org.redisson.api.RCountDownLatch;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.scheduling.quartz.QuartzJobBean;

import java.io.File;
import java.io.IOException;
import java.util.concurrent.TimeUnit;

/**
 * Created by TipDM on 2017/6/28.
 * E-mail:devp@tipdm.com
 */
public class ProjectJobBean extends QuartzJobBean {

    private final Logger LOG = LoggerFactory.getLogger(this.getClass());

    @Autowired
    private ProjectService projectService;

    @Autowired
    private WorkFlowScheduler workFlowScheduler;

    @Autowired
    private TaskService taskService;

    @Autowired
    private TaskScheduler taskScheduler;

    @Override
    protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException {

        JobDataMap jobDataMap = jobExecutionContext.getJobDetail().getJobDataMap();
        Task task = null;
        try {
            task = (Task) jobDataMap.get("task");
        }catch (ClassCastException ex) {
            task = JSON.parseObject(jobDataMap.getString("task"), Task.class);
        }
        String creatorName = task.getCreatorName();
        Long projectId = task.getInstanceId();
        Project project = projectService.findOne(projectId);
        project.setLastOpenTime(java.util.Calendar.getInstance().getTime());
        Document doc = projectService.findDocumentByProjectId(projectId);
        String docDir = RedisUtils.get(com.tipdm.framework.dmserver.utils.Constants.DOCUMENT_DIR, String.class) +"/" + creatorName;
        File parentDir = new File(docDir + "/" + projectService.getRealPathByDocumentId(doc.getParentId()));
        File file = new File(parentDir, project.getName() + ".json");
        String content = null;
        try {
            content = FileUtils.readFileToString(file, Constants.CHARACTER);
        } catch (IOException e) {
            throw new JobExecutionException("流程文件解析出错");
        }
        WorkFlow workFlow = new WorkFlow(creatorName, content);
        try {
            String workFlowId = workFlowScheduler.execute(workFlow);
            RCountDownLatch countDownLatch = RedissonUtils.getRCountDownLatch(workFlowId);
            countDownLatch.trySetCount(1);
            LOG.debug("等待挖掘工程【{}】执行...", project.getName());
            countDownLatch.await(120, TimeUnit.MINUTES);
            LOG.debug("挖掘工程【{}】执行完毕...", project.getName());
        } catch (SchedulerException e) {
            throw new JobExecutionException(e);
        } catch (InterruptedException e) {
            throw new JobExecutionException(e);
        } catch (IllegalAccessException e) {
            throw new JobExecutionException(e);
        }
    }
}
